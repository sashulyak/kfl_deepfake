{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/cvlib-python-package/progressbar-2.5/progressbar-2.5\r\n",
      "Building wheels for collected packages: progressbar\r\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12073 sha256=b8d2ba0ac65582ed9ae7aaac3d6156e3e336cb78aca1c6e7ceed212f5acc91a6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/b8/da/6a7c36dab225b61b697caf74a1c365329bb7a9c80e818d6331\r\n",
      "Successfully built progressbar\r\n",
      "Installing collected packages: progressbar\r\n",
      "Successfully installed progressbar-2.5\r\n",
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/cvlib-python-package/imutils-0.5.3/imutils-0.5.3\r\n",
      "Building wheels for collected packages: imutils\r\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-cp36-none-any.whl size=25851 sha256=3015e8acbe0e2889717acc2119724dd4201a9669ed7d8012573eac525b71cca2\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/77/29/238b7bd7bfc06dc83d3cb0407e349bd6966bfc30887c79cfad\r\n",
      "Successfully built imutils\r\n",
      "Installing collected packages: imutils\r\n",
      "Successfully installed imutils-0.5.3\r\n",
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/cvlib-python-package/cvlib-0.2.3/cvlib-0.2.3\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from cvlib==0.2.3) (1.17.4)\r\n",
      "Requirement already satisfied: progressbar in /opt/conda/lib/python3.6/site-packages (from cvlib==0.2.3) (2.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from cvlib==0.2.3) (2.22.0)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from cvlib==0.2.3) (5.4.1)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from cvlib==0.2.3) (2.3.1)\r\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.6/site-packages (from cvlib==0.2.3) (2.6.1)\r\n",
      "Requirement already satisfied: imutils in /opt/conda/lib/python3.6/site-packages (from cvlib==0.2.3) (0.5.3)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->cvlib==0.2.3) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->cvlib==0.2.3) (1.24.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->cvlib==0.2.3) (2019.9.11)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->cvlib==0.2.3) (2.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras->cvlib==0.2.3) (2.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->cvlib==0.2.3) (5.1.2)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras->cvlib==0.2.3) (1.3.3)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->cvlib==0.2.3) (1.0.8)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras->cvlib==0.2.3) (1.13.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->cvlib==0.2.3) (1.1.0)\r\n",
      "Building wheels for collected packages: cvlib\r\n",
      "  Building wheel for cvlib (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for cvlib: filename=cvlib-0.2.3-cp36-none-any.whl size=10043491 sha256=dc68cddb834d0c993a952e77b180e04375443170dd8b974d8d9c3970aad54777\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/7f/05/c96e1d4add62554197d84c6b83577786a138b1febfb937609a\r\n",
      "Successfully built cvlib\r\n",
      "Installing collected packages: cvlib\r\n",
      "Successfully installed cvlib-0.2.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/cvlib-python-package/progressbar-2.5/progressbar-2.5 -f ./ --no-index\n",
    "!pip install /kaggle/input/cvlib-python-package/imutils-0.5.3/imutils-0.5.3 -f ./ --no-index\n",
    "!pip install /kaggle/input/cvlib-python-package/cvlib-0.2.3/cvlib-0.2.3 -f ./ --no-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "7cb41a99-ac51-40bb-9d86-77ac2885741a",
    "_uuid": "e5aae3c2-d78d-42c8-93ce-9f0a51b86eca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "from typing import List\n",
    "\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "FRAMES_PER_VIDEO = 6\n",
    "TEST_VIDEOS_DIRECTORY = '/kaggle/input/deepfake-detection-challenge/test_videos'\n",
    "PRETRAINED_MODEL_PATH = '/kaggle/input/deepfake-3-faces-resnet50-balanced-classes-weights/deepfake_3_faces_resnet50_balanced_classes.h5'\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_rect_to_square(start_x, start_y, end_x, end_y, image_width, image_height):\n",
    "    width = end_x - start_x\n",
    "    height = end_y - start_y\n",
    "    if width > height:\n",
    "        difference = width - height\n",
    "        start_y -= difference // 2\n",
    "        end_y += difference // 2\n",
    "    else:\n",
    "        difference = height - width\n",
    "        start_x -= difference // 2\n",
    "        end_x += difference // 2\n",
    "    start_x_result = np.max([0, start_x])\n",
    "    start_y_result = np.max([0, start_y])\n",
    "    end_x_result = np.min([image_width, end_x])\n",
    "    end_y_result = np.min([image_height, end_y])\n",
    "\n",
    "    return start_x_result, start_y_result, end_x_result, end_y_result\n",
    "\n",
    "\n",
    "def read_faces_from_video(path: str, img_size=None, swap_channels=True) -> List[str]:\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    num_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    faces_to_save = []\n",
    "    for i in range(0, num_frames):\n",
    "        ret = capture.grab()\n",
    "        if i % 10 == 0:\n",
    "            ret, frame = capture.retrieve()\n",
    "            faces, confidences = cv.detect_face(frame)\n",
    "            if len(confidences) > 0:\n",
    "                most_confident_face_index = np.argmax(confidences)\n",
    "                (start_x, start_y, end_x, end_y) = faces[most_confident_face_index]\n",
    "                (start_x, start_y, end_x, end_y) = extend_rect_to_square(\n",
    "                    start_x,\n",
    "                    start_y,\n",
    "                    end_x,\n",
    "                    end_y,\n",
    "                    frame.shape[1],\n",
    "                    frame.shape[0])\n",
    "                face_crop = frame[start_y:end_y, start_x:end_x]\n",
    "                if face_crop.shape[0] > 0 and face_crop.shape[1] > 0:\n",
    "                    if swap_channels:\n",
    "                        face_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "                    if img_size:\n",
    "                        face_crop = cv2.resize(face_crop, (img_size, img_size))\n",
    "                    faces_to_save.append(face_crop)\n",
    "            if len(faces_to_save) == FRAMES_PER_VIDEO:\n",
    "                break\n",
    "    capture.release()\n",
    "    assert len(faces_to_save) > 0\n",
    "    return faces_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacesDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "            self,\n",
    "            video_file_names: List[str],\n",
    "            videos_directory: str,\n",
    "            video_groups: List[str] = None,\n",
    "            batch_size: int = 64,\n",
    "            frames_per_movie: int = 3,\n",
    "            image_size: int = 200):\n",
    "        self.batch_size = batch_size\n",
    "        self.frames_per_movie = frames_per_movie\n",
    "        self.image_size = image_size\n",
    "        self.video_file_names = video_file_names\n",
    "        self.videos_directory = videos_directory\n",
    "        self.video_groups = video_groups\n",
    "        self.broken_files = []\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(np.ceil(len(self.video_file_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index) -> tuple:\n",
    "        x = []\n",
    "        batch_start = index * self.batch_size\n",
    "        batch_end = min([(index + 1) * self.batch_size, len(video_file_names)])\n",
    "        for i in range(batch_start, batch_end):\n",
    "            filename = self.video_file_names[i]\n",
    "            if self.video_groups is not None:\n",
    "                group_path = os.path.join(self.videos_directory, self.video_groups[i])\n",
    "                video_path = os.path.join(group_path, filename)\n",
    "            else:\n",
    "                video_path = os.path.join(self.videos_directory, filename)\n",
    "\n",
    "            try:\n",
    "                video_frames = read_faces_from_video(video_path, img_size=self.image_size)\n",
    "            except Exception:\n",
    "                self.broken_files.append(filename)\n",
    "                video_frames = np.zeros(shape=(self.frames_per_movie, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "            if len(video_frames) < self.frames_per_movie:\n",
    "                for i in range(self.frames_per_movie - len(video_frames)):\n",
    "                    video_frames.append(video_frames[-1])\n",
    "            x.extend(video_frames)\n",
    "        x = np.array(x) / 255.0\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 430s 17s/step\n"
     ]
    }
   ],
   "source": [
    "video_file_names = np.array(sorted([x for x in os.listdir(TEST_VIDEOS_DIRECTORY) if x[-4:] == \".mp4\"]))\n",
    "data_generator = FacesDataGenerator(\n",
    "    video_file_names=video_file_names,\n",
    "    videos_directory=TEST_VIDEOS_DIRECTORY,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    frames_per_movie=FRAMES_PER_VIDEO,\n",
    "    image_size=IMG_SIZE)\n",
    "\n",
    "model = tf.keras.models.load_model(PRETRAINED_MODEL_PATH)\n",
    "model.run_eagerly = False\n",
    "\n",
    "predictions = model.predict(\n",
    "    data_generator,\n",
    "    verbose=1,\n",
    "    workers=4,\n",
    "    use_multiprocessing=True,\n",
    "    max_queue_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Broken files:', data_generator.broken_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictions[predictions<0.9].shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_grouped = np.reshape(predictions, (len(video_file_names), FRAMES_PER_VIDEO))\n",
    "predictions_mean = np.mean(predictions_grouped, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_file_indexes = np.isin(video_file_names, data_generator.broken_files)\n",
    "predictions_mean[broken_file_indexes] = 0.5\n",
    "all_predictions = np.clip(all_predictions, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"filename\": video_file_names, \"label\": predictions_mean})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}